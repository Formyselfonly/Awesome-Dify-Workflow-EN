app:
  description: "Image Card Link Cardâ€”> User Intent Image Recovery"
  icon: "ðŸ¤–"
  icon_background: '#FFEAD5'
  mode: workflow
  name: "Recover Based on User's Intent Image"
kind: app
version: 0.1.0
workflow:
  features:
    file_upload:
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
    opening_statement: ''
    retriever_resource:
      enabled: false
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        sourceType: llm
        targetType: question-classifier
      id: 1718246807593-1718246909580
      selected: false
      source: '1718246807593'
      sourceHandle: source
      target: '1718246909580'
      targetHandle: target
      type: custom
    - data:
        sourceType: question-classifier
        targetType: llm
      id: 1718246909580-1718246916748
      selected: false
      source: '1718246909580'
      sourceHandle: '1715846546749'
      target: '1718246916748'
      targetHandle: target
      type: custom
    - data:
        isInIteration: false
        sourceType: llm
        targetType: variable-aggregator
      id: 1718246916748-source-1718852940536-target
      source: '1718246916748'
      sourceHandle: source
      target: '1718852940536'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: variable-aggregator
      id: 1718246959048-source-1718852940536-target
      source: '1718246959048'
      sourceHandle: source
      target: '1718852940536'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: variable-aggregator
        targetType: llm
      id: 1718852940536-source-1718853322658-target
      source: '1718852940536'
      sourceHandle: source
      target: '1718853322658'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: start
        targetType: llm
      id: 1714456604511-source-1718246807593-target
      source: '1714456604511'
      sourceHandle: source
      target: '1718246807593'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: llm
        targetType: end
      id: 1718853322658-source-1719901804452-target
      source: '1718853322658'
      sourceHandle: source
      target: '1719901804452'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: question-classifier
        targetType: knowledge-retrieval
      id: 1718246909580-1715846565625-1721623802451-target
      source: '1718246909580'
      sourceHandle: '1715846565625'
      target: '1721623802451'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        sourceType: knowledge-retrieval
        targetType: llm
      id: 1721623802451-source-1718246959048-target
      source: '1721623802451'
      sourceHandle: source
      target: '1718246959048'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: "Start"
        type: start
        variables:
        - label: query
          max_length: 60000
          options: []
          required: true
          type: paragraph
          variable: query
      height: 90
      id: '1714456604511'
      position:
        x: 30
        y: 292
      positionAbsolute:
        x: 30
        y: 292
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        memory:
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
            size: 3
        model:
          completion_params:
            temperature: 0.7
            top_p: 0.2
          mode: chat
          name: qwen-vl-plus
          provider: tongyi
        prompt_template:
        - id: cf4669d8-da9b-43e6-a726-989dd4dacdc9
          role: system
          text: "Now I am going to create a conversation information processing task, please refer to the following Prompt instructions.\n"
        - id: 4cd9313f-e470-4abd-96ba-0f396be97a9d
          role: user
          text: "## Character\nYou are a customer service of an app that has already been set up with a business store, and it also has an assistant tool that can track the heart rate in real-time. You are responsible for providing customer service.\n\n## Input:\n- Input content is the user's chat log.\n- It may include multiple paragraphs of text and images\n- This content relates to the App, operations, food, questions, or daily life.\n\n## Strategy:\nThe strategy is to conduct information processing in four steps, and print each step's result; do not skip:\n1. If there is an image, analyze the content of the image and classify it, for example: food, app screenshots, operation tool belts, etc.\n2. Merge the content of the text, give a detailed description of the image.\n3. Based on the interpretation of the text and the description of the image, try to conduct a full conversation with the user, pointing out the user's intent. For example: discuss the card-sharing, health consultation, chatting with friends online, asking about food recommendations, exercise belt-related questions.\n4. Based on the user's intent, provide the response strategy. For example: recommend a prize for the user, give health advice, or assist with app or belt usage.\n- Purely image classification, the general rate needs to be winning prizes.\n- For health-related issues, the general rate should focus on professional health advice and guidance.\n- For app and belt-related issues, the general rate requires knowledge of the knowledge base and support assistance.\n- Text information's image_type only serves as reference, do not involve analysis\n## Format\nReturn the format as follows, with placeholders indicated by '{xxx}':\n### Image Classification\n{Image Classification}\n***\n### Image Description\n{Image Description}\n***\n### User Intent Image\n{User Intent Image}\n***\n### Recovery Strategy\n{Recovery Strategy}"
        - id: 04e30b4d-8f79-4837-b470-bd46ae52a1bb
          role: assistant
          text: "Good, I will proceed with processing your request as per the instructions."
        - id: 7a805718-5f13-4bd4-9995-b466b56f4735
          role: user
          text: '{{#1714456604511.query#}}'
        selected: false
        title: "Intent Image Processor"
        type: llm
        variables: []
        vision:
          configs:
            detail: high
          enabled: true
      height: 98
      id: '1718246807593'
      position:
        x: 334
        y: 292
      positionAbsolute:
        x: 334
        y: 292
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        classes:
        - id: '1715846546749'
          name: "Health Consultation"
        - id: '1715846565625'
          name: "User Assistance"
        desc: ''
        instruction: "Classification depends on:\n- For app, operation tool belts related, belongs to **User Assistance**\n- For health, food, sleep, and other categories, belongs to **Health Consultation**"
        instructions: ''
        model:
          completion_params:
            temperature: 0.1
            top_p: 1
          mode
